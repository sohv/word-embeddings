{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPE8UbtnnUDi"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0-S8avU69_lV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pickle\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import random\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2B1zaXtY-URG"
      },
      "source": [
        "# Pre-trained Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1PZb3n3NN2x"
      },
      "source": [
        "## Load embeddings\n",
        "\n",
        "We load pre-trained embeddings of GLoVe [1] and Word2Vec [2] from their sources and save them in our memory. From [1] and [2] we observe that the optimal dimension for saving the embeddings is 300 (which is implemented in this code as well).\n",
        "\n",
        "For GLoVe embeddings source, go [here](https://nlp.stanford.edu/projects/glove/) (You can directly download the embeddings by running the below cell).\n",
        "\n",
        "For Word2Vec embeddings, download the zip file from [here](https://www.kaggle.com/datasets/pkugoodspeed/nlpword2vecembeddingspretrained) and store it in a folder named word2vec. The extraction and loading of embeddings will be done below.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNvts6bTpY04"
      },
      "source": [
        "### Load GLoVe\n",
        "\n",
        "Before proceeding further, confirm if you have downloaded a total of 400000 word embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "9h1XAgBlKUkk",
        "outputId": "e8adeca2-5c8b-4e3d-a56b-3b96408e7a40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading GloVe embeddings from https://nlp.stanford.edu/data/glove.6B.zip...\n",
            "Downloaded file to /content/drive/MyDrive/Colab Notebooks/code/models/pre-trained/glove/glove.6B.zip\n",
            "Extracting glove.6B.300d.txt...\n",
            "Extracted to /content/drive/MyDrive/Colab Notebooks/code/models/pre-trained/glove/glove.6B.300d.txt\n",
            "Loaded 10000 embeddings\n",
            "Loaded 20000 embeddings\n",
            "Loaded 30000 embeddings\n",
            "Loaded 40000 embeddings\n",
            "Loaded 50000 embeddings\n",
            "Loaded 60000 embeddings\n",
            "Loaded 70000 embeddings\n",
            "Loaded 80000 embeddings\n",
            "Loaded 90000 embeddings\n",
            "Loaded 100000 embeddings\n",
            "Loaded 110000 embeddings\n",
            "Loaded 120000 embeddings\n",
            "Loaded 130000 embeddings\n",
            "Loaded 140000 embeddings\n",
            "Loaded 150000 embeddings\n",
            "Loaded 160000 embeddings\n",
            "Loaded 170000 embeddings\n",
            "Loaded 180000 embeddings\n",
            "Loaded 190000 embeddings\n",
            "Loaded 200000 embeddings\n",
            "Loaded 210000 embeddings\n",
            "Loaded 220000 embeddings\n",
            "Loaded 230000 embeddings\n",
            "Loaded 240000 embeddings\n",
            "Loaded 250000 embeddings\n",
            "Loaded 260000 embeddings\n",
            "Loaded 270000 embeddings\n",
            "Loaded 280000 embeddings\n",
            "Loaded 290000 embeddings\n",
            "Loaded 300000 embeddings\n",
            "Loaded 310000 embeddings\n",
            "Loaded 320000 embeddings\n",
            "Loaded 330000 embeddings\n",
            "Loaded 340000 embeddings\n",
            "Loaded 350000 embeddings\n",
            "Loaded 360000 embeddings\n",
            "Loaded 370000 embeddings\n",
            "Loaded 380000 embeddings\n",
            "Loaded 390000 embeddings\n",
            "Loaded 400000 embeddings\n",
            "Successfully loaded 400000 embeddings.\n",
            "Saved embeddings to /content/drive/MyDrive/Colab Notebooks/code/models/pre-trained/glove/glove_6B_300d.pkl\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import requests\n",
        "import zipfile\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "def download_glove(dim=300, save_dir='/content/drive/MyDrive/Colab Notebooks/code/models/pre-trained/glove'):\n",
        "    if dim not in [50, 100, 200, 300]:\n",
        "        raise ValueError(\"Embedding dimension must be one of: 50, 100, 200, 300\")\n",
        "\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    url = \"https://nlp.stanford.edu/data/glove.6B.zip\"\n",
        "    zip_path = os.path.join(save_dir, \"glove.6B.zip\")\n",
        "\n",
        "    if not os.path.exists(zip_path):\n",
        "        print(f\"Downloading GloVe embeddings from {url}...\")\n",
        "        response = requests.get(url, stream=True)\n",
        "        response.raise_for_status()\n",
        "        with open(zip_path, 'wb') as f:\n",
        "            for chunk in response.iter_content(chunk_size=8192):\n",
        "                f.write(chunk)\n",
        "        print(f\"Downloaded file to {zip_path}\")\n",
        "    else:\n",
        "        print(f\"File already exists at {zip_path}\")\n",
        "\n",
        "    embed_file = f\"glove.6B.{dim}d.txt\"\n",
        "    extract_path = os.path.join(save_dir, embed_file)\n",
        "\n",
        "    if not os.path.exists(extract_path):\n",
        "        print(f\"Extracting {embed_file}...\")\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            matching_files = [f for f in zip_ref.namelist() if f.endswith(f\"{dim}d.txt\")]\n",
        "            if not matching_files:\n",
        "                raise ValueError(f\"No embedding file found with dimension {dim}\")\n",
        "\n",
        "            zip_ref.extract(matching_files[0], save_dir)\n",
        "            extracted_file = os.path.join(save_dir, matching_files[0])\n",
        "            if extracted_file != extract_path:\n",
        "                os.rename(extracted_file, extract_path)\n",
        "        print(f\"Extracted to {extract_path}\")\n",
        "    else:\n",
        "        print(f\"Embeddings already extracted at {extract_path}\")\n",
        "\n",
        "    embeddings = {}\n",
        "    with open(extract_path, 'r', encoding='utf-8') as f:\n",
        "        for i, line in enumerate(f):\n",
        "            values = line.strip().split()\n",
        "            word = values[0]\n",
        "            vector = np.array(values[1:], dtype=np.float32)\n",
        "            embeddings[word] = vector\n",
        "            if (i + 1) % 10000 == 0:\n",
        "                print(f\"Loaded {i + 1} embeddings\")\n",
        "\n",
        "    print(f\"Successfully loaded {len(embeddings)} embeddings.\")\n",
        "\n",
        "    pkl_path = os.path.join(save_dir, f\"glove_6B_{dim}d.pkl\")\n",
        "    with open(pkl_path, 'wb') as f:\n",
        "        pickle.dump(embeddings, f)\n",
        "    print(f\"Saved embeddings to {pkl_path}\")\n",
        "\n",
        "    return embeddings\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    glove_embeddings = download_glove(dim=300)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KMHdbBFOI_l"
      },
      "source": [
        "### Load Word2Vec embeddings\n",
        "\n",
        "There are a total of 3000000 word embeddings in Word2Vec, so confirm it before proceeding further."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ohvfcAh3OIeQ",
        "outputId": "b0dce630-52b7-4731-b932-0d0321357ff8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting /content/drive/MyDrive/Colab Notebooks/code/models/pre-trained/GoogleNews-vectors-negative300.bin.zip to /content/drive/MyDrive/Colab Notebooks/code/models/pre-trained...\n",
            "Files in archive: ['GoogleNews-vectors-negative300.bin']\n",
            "Extracting GoogleNews-vectors-negative300.bin...\n",
            "Extracted to /content/drive/MyDrive/Colab Notebooks/code/models/pre-trained/GoogleNews-vectors-negative300.bin\n",
            "Loading embeddings from /content/drive/MyDrive/Colab Notebooks/code/models/pre-trained/GoogleNews-vectors-negative300.bin\n",
            "Vocabulary size: 3000000, Vector dimension: 300\n",
            "Loaded 0/3000000 word vectors\n",
            "Loaded 10000/3000000 word vectors\n",
            "Loaded 20000/3000000 word vectors\n",
            "Loaded 30000/3000000 word vectors\n",
            "Loaded 40000/3000000 word vectors\n",
            "Loaded 50000/3000000 word vectors\n",
            "Loaded 60000/3000000 word vectors\n",
            "Loaded 70000/3000000 word vectors\n",
            "Loaded 80000/3000000 word vectors\n",
            "Loaded 90000/3000000 word vectors\n",
            "Loaded 100000/3000000 word vectors\n",
            "Loaded 110000/3000000 word vectors\n",
            "Loaded 120000/3000000 word vectors\n",
            "Loaded 130000/3000000 word vectors\n",
            "Loaded 140000/3000000 word vectors\n",
            "Loaded 150000/3000000 word vectors\n",
            "Loaded 160000/3000000 word vectors\n",
            "Loaded 170000/3000000 word vectors\n",
            "Loaded 180000/3000000 word vectors\n",
            "Loaded 190000/3000000 word vectors\n",
            "Loaded 200000/3000000 word vectors\n",
            "Loaded 210000/3000000 word vectors\n",
            "Loaded 220000/3000000 word vectors\n",
            "Loaded 230000/3000000 word vectors\n",
            "Loaded 240000/3000000 word vectors\n",
            "Loaded 250000/3000000 word vectors\n",
            "Loaded 260000/3000000 word vectors\n",
            "Loaded 270000/3000000 word vectors\n",
            "Loaded 280000/3000000 word vectors\n",
            "Loaded 290000/3000000 word vectors\n",
            "Loaded 300000/3000000 word vectors\n",
            "Loaded 310000/3000000 word vectors\n",
            "Loaded 320000/3000000 word vectors\n",
            "Loaded 330000/3000000 word vectors\n",
            "Loaded 340000/3000000 word vectors\n",
            "Loaded 350000/3000000 word vectors\n",
            "Loaded 360000/3000000 word vectors\n",
            "Loaded 370000/3000000 word vectors\n",
            "Loaded 380000/3000000 word vectors\n",
            "Loaded 390000/3000000 word vectors\n",
            "Loaded 400000/3000000 word vectors\n",
            "Loaded 410000/3000000 word vectors\n",
            "Loaded 420000/3000000 word vectors\n",
            "Loaded 430000/3000000 word vectors\n",
            "Loaded 440000/3000000 word vectors\n",
            "Loaded 450000/3000000 word vectors\n",
            "Loaded 460000/3000000 word vectors\n",
            "Loaded 470000/3000000 word vectors\n",
            "Loaded 480000/3000000 word vectors\n",
            "Loaded 490000/3000000 word vectors\n",
            "Loaded 500000/3000000 word vectors\n",
            "Loaded 510000/3000000 word vectors\n",
            "Loaded 520000/3000000 word vectors\n",
            "Loaded 530000/3000000 word vectors\n",
            "Loaded 540000/3000000 word vectors\n",
            "Loaded 550000/3000000 word vectors\n",
            "Loaded 560000/3000000 word vectors\n",
            "Loaded 570000/3000000 word vectors\n",
            "Loaded 580000/3000000 word vectors\n",
            "Loaded 590000/3000000 word vectors\n",
            "Loaded 600000/3000000 word vectors\n",
            "Loaded 610000/3000000 word vectors\n",
            "Loaded 620000/3000000 word vectors\n",
            "Loaded 630000/3000000 word vectors\n",
            "Loaded 640000/3000000 word vectors\n",
            "Loaded 650000/3000000 word vectors\n",
            "Loaded 660000/3000000 word vectors\n",
            "Loaded 670000/3000000 word vectors\n",
            "Loaded 680000/3000000 word vectors\n",
            "Loaded 690000/3000000 word vectors\n",
            "Loaded 700000/3000000 word vectors\n",
            "Loaded 710000/3000000 word vectors\n",
            "Loaded 720000/3000000 word vectors\n",
            "Loaded 730000/3000000 word vectors\n",
            "Loaded 740000/3000000 word vectors\n",
            "Loaded 750000/3000000 word vectors\n",
            "Loaded 760000/3000000 word vectors\n",
            "Loaded 770000/3000000 word vectors\n",
            "Loaded 780000/3000000 word vectors\n",
            "Loaded 790000/3000000 word vectors\n",
            "Loaded 800000/3000000 word vectors\n",
            "Loaded 810000/3000000 word vectors\n",
            "Loaded 820000/3000000 word vectors\n",
            "Loaded 830000/3000000 word vectors\n",
            "Loaded 840000/3000000 word vectors\n",
            "Loaded 850000/3000000 word vectors\n",
            "Loaded 860000/3000000 word vectors\n",
            "Loaded 870000/3000000 word vectors\n",
            "Loaded 880000/3000000 word vectors\n",
            "Loaded 890000/3000000 word vectors\n",
            "Loaded 900000/3000000 word vectors\n",
            "Loaded 910000/3000000 word vectors\n",
            "Loaded 920000/3000000 word vectors\n",
            "Loaded 930000/3000000 word vectors\n",
            "Loaded 940000/3000000 word vectors\n",
            "Loaded 950000/3000000 word vectors\n",
            "Loaded 960000/3000000 word vectors\n",
            "Loaded 970000/3000000 word vectors\n",
            "Loaded 980000/3000000 word vectors\n",
            "Loaded 990000/3000000 word vectors\n",
            "Loaded 1000000/3000000 word vectors\n",
            "Loaded 1010000/3000000 word vectors\n",
            "Loaded 1020000/3000000 word vectors\n",
            "Loaded 1030000/3000000 word vectors\n",
            "Loaded 1040000/3000000 word vectors\n",
            "Loaded 1050000/3000000 word vectors\n",
            "Loaded 1060000/3000000 word vectors\n",
            "Loaded 1070000/3000000 word vectors\n",
            "Loaded 1080000/3000000 word vectors\n",
            "Loaded 1090000/3000000 word vectors\n",
            "Loaded 1100000/3000000 word vectors\n",
            "Loaded 1110000/3000000 word vectors\n",
            "Loaded 1120000/3000000 word vectors\n",
            "Loaded 1130000/3000000 word vectors\n",
            "Loaded 1140000/3000000 word vectors\n",
            "Loaded 1150000/3000000 word vectors\n",
            "Loaded 1160000/3000000 word vectors\n",
            "Loaded 1170000/3000000 word vectors\n",
            "Loaded 1180000/3000000 word vectors\n",
            "Loaded 1190000/3000000 word vectors\n",
            "Loaded 1200000/3000000 word vectors\n",
            "Loaded 1210000/3000000 word vectors\n",
            "Loaded 1220000/3000000 word vectors\n",
            "Loaded 1230000/3000000 word vectors\n",
            "Loaded 1240000/3000000 word vectors\n",
            "Loaded 1250000/3000000 word vectors\n",
            "Loaded 1260000/3000000 word vectors\n",
            "Loaded 1270000/3000000 word vectors\n",
            "Loaded 1280000/3000000 word vectors\n",
            "Loaded 1290000/3000000 word vectors\n",
            "Loaded 1300000/3000000 word vectors\n",
            "Loaded 1310000/3000000 word vectors\n",
            "Loaded 1320000/3000000 word vectors\n",
            "Loaded 1330000/3000000 word vectors\n",
            "Loaded 1340000/3000000 word vectors\n",
            "Loaded 1350000/3000000 word vectors\n",
            "Loaded 1360000/3000000 word vectors\n",
            "Loaded 1370000/3000000 word vectors\n",
            "Loaded 1380000/3000000 word vectors\n",
            "Loaded 1390000/3000000 word vectors\n",
            "Loaded 1400000/3000000 word vectors\n",
            "Loaded 1410000/3000000 word vectors\n",
            "Loaded 1420000/3000000 word vectors\n",
            "Loaded 1430000/3000000 word vectors\n",
            "Loaded 1440000/3000000 word vectors\n",
            "Loaded 1450000/3000000 word vectors\n",
            "Loaded 1460000/3000000 word vectors\n",
            "Loaded 1470000/3000000 word vectors\n",
            "Loaded 1480000/3000000 word vectors\n",
            "Loaded 1490000/3000000 word vectors\n",
            "Loaded 1500000/3000000 word vectors\n",
            "Loaded 1510000/3000000 word vectors\n",
            "Loaded 1520000/3000000 word vectors\n",
            "Loaded 1530000/3000000 word vectors\n",
            "Loaded 1540000/3000000 word vectors\n",
            "Loaded 1550000/3000000 word vectors\n",
            "Loaded 1560000/3000000 word vectors\n",
            "Loaded 1570000/3000000 word vectors\n",
            "Loaded 1580000/3000000 word vectors\n",
            "Loaded 1590000/3000000 word vectors\n",
            "Loaded 1600000/3000000 word vectors\n",
            "Loaded 1610000/3000000 word vectors\n",
            "Loaded 1620000/3000000 word vectors\n",
            "Loaded 1630000/3000000 word vectors\n",
            "Loaded 1640000/3000000 word vectors\n",
            "Loaded 1650000/3000000 word vectors\n",
            "Loaded 1660000/3000000 word vectors\n",
            "Loaded 1670000/3000000 word vectors\n",
            "Loaded 1680000/3000000 word vectors\n",
            "Loaded 1690000/3000000 word vectors\n",
            "Loaded 1700000/3000000 word vectors\n",
            "Loaded 1710000/3000000 word vectors\n",
            "Loaded 1720000/3000000 word vectors\n",
            "Loaded 1730000/3000000 word vectors\n",
            "Loaded 1740000/3000000 word vectors\n",
            "Loaded 1750000/3000000 word vectors\n",
            "Loaded 1760000/3000000 word vectors\n",
            "Loaded 1770000/3000000 word vectors\n",
            "Loaded 1780000/3000000 word vectors\n",
            "Loaded 1790000/3000000 word vectors\n",
            "Loaded 1800000/3000000 word vectors\n",
            "Loaded 1810000/3000000 word vectors\n",
            "Loaded 1820000/3000000 word vectors\n",
            "Loaded 1830000/3000000 word vectors\n",
            "Loaded 1840000/3000000 word vectors\n",
            "Loaded 1850000/3000000 word vectors\n",
            "Loaded 1860000/3000000 word vectors\n",
            "Loaded 1870000/3000000 word vectors\n",
            "Loaded 1880000/3000000 word vectors\n",
            "Loaded 1890000/3000000 word vectors\n",
            "Loaded 1900000/3000000 word vectors\n",
            "Loaded 1910000/3000000 word vectors\n",
            "Loaded 1920000/3000000 word vectors\n",
            "Loaded 1930000/3000000 word vectors\n",
            "Loaded 1940000/3000000 word vectors\n",
            "Loaded 1950000/3000000 word vectors\n",
            "Loaded 1960000/3000000 word vectors\n",
            "Loaded 1970000/3000000 word vectors\n",
            "Loaded 1980000/3000000 word vectors\n",
            "Loaded 1990000/3000000 word vectors\n",
            "Loaded 2000000/3000000 word vectors\n",
            "Loaded 2010000/3000000 word vectors\n",
            "Loaded 2020000/3000000 word vectors\n",
            "Loaded 2030000/3000000 word vectors\n",
            "Loaded 2040000/3000000 word vectors\n",
            "Loaded 2050000/3000000 word vectors\n",
            "Loaded 2060000/3000000 word vectors\n",
            "Loaded 2070000/3000000 word vectors\n",
            "Loaded 2080000/3000000 word vectors\n",
            "Loaded 2090000/3000000 word vectors\n",
            "Loaded 2100000/3000000 word vectors\n",
            "Loaded 2110000/3000000 word vectors\n",
            "Loaded 2120000/3000000 word vectors\n",
            "Loaded 2130000/3000000 word vectors\n",
            "Loaded 2140000/3000000 word vectors\n",
            "Loaded 2150000/3000000 word vectors\n",
            "Loaded 2160000/3000000 word vectors\n",
            "Loaded 2170000/3000000 word vectors\n",
            "Loaded 2180000/3000000 word vectors\n",
            "Loaded 2190000/3000000 word vectors\n",
            "Loaded 2200000/3000000 word vectors\n",
            "Loaded 2210000/3000000 word vectors\n",
            "Loaded 2220000/3000000 word vectors\n",
            "Loaded 2230000/3000000 word vectors\n",
            "Loaded 2240000/3000000 word vectors\n",
            "Loaded 2250000/3000000 word vectors\n",
            "Loaded 2260000/3000000 word vectors\n",
            "Loaded 2270000/3000000 word vectors\n",
            "Loaded 2280000/3000000 word vectors\n",
            "Loaded 2290000/3000000 word vectors\n",
            "Loaded 2300000/3000000 word vectors\n",
            "Loaded 2310000/3000000 word vectors\n",
            "Loaded 2320000/3000000 word vectors\n",
            "Loaded 2330000/3000000 word vectors\n",
            "Loaded 2340000/3000000 word vectors\n",
            "Loaded 2350000/3000000 word vectors\n",
            "Loaded 2360000/3000000 word vectors\n",
            "Loaded 2370000/3000000 word vectors\n",
            "Loaded 2380000/3000000 word vectors\n",
            "Loaded 2390000/3000000 word vectors\n",
            "Loaded 2400000/3000000 word vectors\n",
            "Loaded 2410000/3000000 word vectors\n",
            "Loaded 2420000/3000000 word vectors\n",
            "Loaded 2430000/3000000 word vectors\n",
            "Loaded 2440000/3000000 word vectors\n",
            "Loaded 2450000/3000000 word vectors\n",
            "Loaded 2460000/3000000 word vectors\n",
            "Loaded 2470000/3000000 word vectors\n",
            "Loaded 2480000/3000000 word vectors\n",
            "Loaded 2490000/3000000 word vectors\n",
            "Loaded 2500000/3000000 word vectors\n",
            "Loaded 2510000/3000000 word vectors\n",
            "Loaded 2520000/3000000 word vectors\n",
            "Loaded 2530000/3000000 word vectors\n",
            "Loaded 2540000/3000000 word vectors\n",
            "Loaded 2550000/3000000 word vectors\n",
            "Loaded 2560000/3000000 word vectors\n",
            "Loaded 2570000/3000000 word vectors\n",
            "Loaded 2580000/3000000 word vectors\n",
            "Loaded 2590000/3000000 word vectors\n",
            "Loaded 2600000/3000000 word vectors\n",
            "Loaded 2610000/3000000 word vectors\n",
            "Loaded 2620000/3000000 word vectors\n",
            "Loaded 2630000/3000000 word vectors\n",
            "Loaded 2640000/3000000 word vectors\n",
            "Loaded 2650000/3000000 word vectors\n",
            "Loaded 2660000/3000000 word vectors\n",
            "Loaded 2670000/3000000 word vectors\n",
            "Loaded 2680000/3000000 word vectors\n",
            "Loaded 2690000/3000000 word vectors\n",
            "Loaded 2700000/3000000 word vectors\n",
            "Loaded 2710000/3000000 word vectors\n",
            "Loaded 2720000/3000000 word vectors\n",
            "Loaded 2730000/3000000 word vectors\n",
            "Loaded 2740000/3000000 word vectors\n",
            "Loaded 2750000/3000000 word vectors\n",
            "Loaded 2760000/3000000 word vectors\n",
            "Loaded 2770000/3000000 word vectors\n",
            "Loaded 2780000/3000000 word vectors\n",
            "Loaded 2790000/3000000 word vectors\n",
            "Loaded 2800000/3000000 word vectors\n",
            "Loaded 2810000/3000000 word vectors\n",
            "Loaded 2820000/3000000 word vectors\n",
            "Loaded 2830000/3000000 word vectors\n",
            "Loaded 2840000/3000000 word vectors\n",
            "Loaded 2850000/3000000 word vectors\n",
            "Loaded 2860000/3000000 word vectors\n",
            "Loaded 2870000/3000000 word vectors\n",
            "Loaded 2880000/3000000 word vectors\n",
            "Loaded 2890000/3000000 word vectors\n",
            "Loaded 2900000/3000000 word vectors\n",
            "Loaded 2910000/3000000 word vectors\n",
            "Loaded 2920000/3000000 word vectors\n",
            "Loaded 2930000/3000000 word vectors\n",
            "Loaded 2940000/3000000 word vectors\n",
            "Loaded 2950000/3000000 word vectors\n",
            "Loaded 2960000/3000000 word vectors\n",
            "Loaded 2970000/3000000 word vectors\n",
            "Loaded 2980000/3000000 word vectors\n",
            "Loaded 2990000/3000000 word vectors\n",
            "Successfully loaded 3000000 word vectors\n",
            "Saving embeddings to /content/drive/MyDrive/Colab Notebooks/code/models/pre-trained/word2vec/word2vec_googleNews_300d.pkl\n",
            "Embeddings saved successfully\n",
            "Loaded and saved 3000000 Word2Vec embeddings to Google Drive\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import struct\n",
        "import os\n",
        "import pickle\n",
        "import zipfile\n",
        "\n",
        "def load_word2vec_binary(file_path, save_path=None):\n",
        "    embeddings = {}\n",
        "\n",
        "    print(f\"Loading embeddings from {file_path}\")\n",
        "    with open(file_path, 'rb') as f:\n",
        "        header = f.readline().decode('utf-8').strip().split()\n",
        "        vocab_size = int(header[0])\n",
        "        vector_size = int(header[1])\n",
        "\n",
        "        print(f\"Vocabulary size: {vocab_size}, Vector dimension: {vector_size}\")\n",
        "\n",
        "        for i in range(vocab_size):\n",
        "            if i % 10000 == 0:\n",
        "                print(f\"Loaded {i}/{vocab_size} word vectors\")\n",
        "\n",
        "            word = b''\n",
        "            char = f.read(1)\n",
        "            while char != b' ' and char != b'\\n':\n",
        "                word += char\n",
        "                char = f.read(1)\n",
        "\n",
        "            word = word.decode('utf-8', errors='ignore')\n",
        "            vector = np.array(struct.unpack(f'{vector_size}f', f.read(vector_size * 4)), dtype=np.float32)\n",
        "            embeddings[word] = vector\n",
        "\n",
        "    print(f\"Successfully loaded {len(embeddings)} word vectors\")\n",
        "\n",
        "    if save_path:\n",
        "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "        print(f\"Saving embeddings to {save_path}\")\n",
        "        with open(save_path, 'wb') as f:\n",
        "            pickle.dump(embeddings, f)\n",
        "        print(\"Embeddings saved successfully\")\n",
        "\n",
        "    return embeddings\n",
        "\n",
        "def extract_word2vec_from_zip(zip_path, extract_dir=None):\n",
        "    if extract_dir is None:\n",
        "        extract_dir = os.path.dirname(zip_path)\n",
        "\n",
        "    print(f\"Extracting {zip_path} to {extract_dir}...\")\n",
        "\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        file_list = zip_ref.namelist()\n",
        "        print(f\"Files in archive: {file_list}\")\n",
        "\n",
        "        bin_files = [f for f in file_list if f.endswith('.bin')]\n",
        "        if not bin_files:\n",
        "            raise ValueError(\"No .bin file found in the zip archive\")\n",
        "\n",
        "        bin_file = bin_files[0]\n",
        "        print(f\"Extracting {bin_file}...\")\n",
        "\n",
        "        zip_ref.extract(bin_file, extract_dir)\n",
        "\n",
        "    bin_path = os.path.join(extract_dir, bin_file)\n",
        "    print(f\"Extracted to {bin_path}\")\n",
        "\n",
        "    return bin_path\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    save_dir = '/content/drive/MyDrive/Colab Notebooks/code/models/pre-trained/word2vec'\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    data_dir = '/content/drive/MyDrive/Colab Notebooks/code/models/pre-trained'\n",
        "    os.makedirs(data_dir, exist_ok=True)\n",
        "\n",
        "    zip_path = os.path.join(data_dir, \"GoogleNews-vectors-negative300.bin.zip\")\n",
        "    bin_path = extract_word2vec_from_zip(zip_path, extract_dir=data_dir)\n",
        "    save_path = os.path.join(save_dir, \"word2vec_googleNews_300d.pkl\")\n",
        "    word2vec_embeddings = load_word2vec_binary(bin_path, save_path=save_path)\n",
        "    print(f\"Loaded and saved {len(word2vec_embeddings)} Word2Vec embeddings to Google Drive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QQo9tPKp06C"
      },
      "source": [
        "### Defining paths\n",
        "\n",
        "Copy the paths of newly created.pkl files of GLoVe and Word2Vec embeddings in GLOVE_PATH and WORD2VEC_PATH respectively and define two variables to easily reference the paths in the future."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VYxrmnDTFRu",
        "outputId": "462b2565-2374-44a1-884a-1c79e772befa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading embeddings from /content/drive/MyDrive/Colab Notebooks/code/models/pre-trained/glove/glove_6B_300d.pkl...\n",
            "Loaded 400000 word vectors\n",
            "Loading embeddings from /content/drive/MyDrive/Colab Notebooks/code/models/pre-trained/word2vec/word2vec_googleNews_300d.pkl...\n",
            "Loaded 3000000 word vectors\n"
          ]
        }
      ],
      "source": [
        "GLOVE_PATH = '/content/drive/MyDrive/Colab Notebooks/code/models/pre-trained/glove/glove_6B_300d.pkl'\n",
        "WORD2VEC_PATH = '/content/drive/MyDrive/Colab Notebooks/code/models/pre-trained/word2vec/word2vec_googleNews_300d.pkl'\n",
        "\n",
        "def load_embeddings(path):\n",
        "    print(f\"Loading embeddings from {path}...\")\n",
        "    with open(path, 'rb') as f:\n",
        "        embeddings = pickle.load(f)\n",
        "    print(f\"Loaded {len(embeddings)} word vectors\")\n",
        "    return embeddings\n",
        "\n",
        "glove = load_embeddings(GLOVE_PATH)\n",
        "word2vec = load_embeddings(WORD2VEC_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBUUVx_S_YX0"
      },
      "source": [
        "### Inspect embeddings\n",
        "\n",
        "You can load the path of embeddings file in last line of below cell to inspect its structure and get a better idea of shape and size of the file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9_y9jmB_I5i",
        "outputId": "62f9ad24-0294-4e35-fac6-4c4160d8437e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total embeddings: 3000000\n",
            "Vector dimension: 300\n",
            "Sample word: '</s>' → Vector shape: (300,)\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "def inspect_pkl_embeddings(filepath):\n",
        "    with open(filepath, 'rb') as f:\n",
        "        embeddings = pickle.load(f)\n",
        "\n",
        "    sample_word, sample_vector = next(iter(embeddings.items()))\n",
        "\n",
        "    print(f\"Total embeddings: {len(embeddings)}\")\n",
        "    print(f\"Vector dimension: {sample_vector.shape[0]}\")\n",
        "    print(f\"Sample word: '{sample_word}' → Vector shape: {sample_vector.shape}\")\n",
        "\n",
        "inspect_pkl_embeddings(\"/content/drive/MyDrive/Colab Notebooks/code/models/pre-trained/word2vec/word2vec_googleNews_300d.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmpBhl-8_vum"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyJfc250q5MT"
      },
      "source": [
        "## Helper functions\n",
        "\n",
        "We define a few helper functions to carry out essential tasks needed for further analysis, so that we don't have to code each function separately every time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "brVjALY9Txee"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Find and return the vector representation of each word from the pre-trained embeddings dictionary\n",
        "'''\n",
        "def get_word_vector(word, embeddings):\n",
        "    if word in embeddings:\n",
        "        return embeddings[word]\n",
        "    if word.lower() in embeddings:\n",
        "        return embeddings[word.lower()]\n",
        "    if word.capitalize() in embeddings:\n",
        "        return embeddings[word.capitalize()]\n",
        "    if word.upper() in embeddings:\n",
        "        return embeddings[word.upper()]\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BgO-7DgKT2D3"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Measure the cosine similarity between two vectors to measure similarity between them\n",
        "'''\n",
        "def cosine_sim(vec1, vec2):\n",
        "    if vec1 is None or vec2 is None:\n",
        "        return None\n",
        "    norm1 = np.linalg.norm(vec1)\n",
        "    norm2 = np.linalg.norm(vec2)\n",
        "    if norm1 == 0 or norm2 == 0:\n",
        "        return 0\n",
        "    return np.dot(vec1, vec2) / (norm1 * norm2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "YOU_AYGqT8BG"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Checks the words against a given embedding dictionary to identify what words are missing ('Out of Vocabulary' words).\n",
        "'''\n",
        "def check_vocabulary(word_list, embeddings, embedding_name):\n",
        "    missing = [word for word in word_list if get_word_vector(word, embeddings) is None]\n",
        "    if missing:\n",
        "        print(f\"Words missing in {embedding_name}: {missing}\")\n",
        "    return len(word_list) - len(missing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuMu37Efrvqa"
      },
      "source": [
        "## WEAT test\n",
        "\n",
        "\n",
        "\n",
        "*   Word Embedding Association Test (WEAT) is a test to examine the associations in word embeddings between concepts (like bias) [3]. WEAT uses the Implicit Association Test (IAT) from psychology to word embeddings, providing a statistical framework to detect bias [4].\n",
        "*   With the help of [5], the following test is done for two sets of target words (X,Y) and attribute words (A,B) and effect_size (which measures bias magnitude) and p-value (statistical significance) are computed.\n",
        "\n",
        "*   The format 'Target, Attribute' is chosen to facilitate easy evaluation of how strongly the concepts(gender specific roles) are associated with its attributes (profession, feeling etc).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1amuwnshwjyU"
      },
      "source": [
        "### WEAT test function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3GtWsHTUKYn"
      },
      "outputs": [],
      "source": [
        "def weat_test(X, Y, A, B, embeddings):\n",
        "    X_valid = [x for x in X if get_word_vector(x, embeddings) is not None]\n",
        "    Y_valid = [y for y in Y if get_word_vector(y, embeddings) is not None]\n",
        "    A_valid = [a for a in A if get_word_vector(a, embeddings) is not None]\n",
        "    B_valid = [b for b in B if get_word_vector(b, embeddings) is not None]\n",
        "\n",
        "    if len(X_valid) == 0 or len(Y_valid) == 0 or len(A_valid) == 0 or len(B_valid) == 0:\n",
        "        return None, None\n",
        "\n",
        "    # association between each target word and attribute sets\n",
        "    def association(w, A, B):\n",
        "        w_vec = get_word_vector(w, embeddings)\n",
        "        A_sims = [cosine_sim(w_vec, get_word_vector(a, embeddings)) for a in A_valid]\n",
        "        B_sims = [cosine_sim(w_vec, get_word_vector(b, embeddings)) for b in B_valid]\n",
        "        return np.mean(A_sims) - np.mean(B_sims)\n",
        "\n",
        "    X_associations = [association(x, A_valid, B_valid) for x in X_valid]\n",
        "    Y_associations = [association(y, A_valid, B_valid) for y in Y_valid]\n",
        "    test_statistic = np.mean(X_associations) - np.mean(Y_associations)\n",
        "\n",
        "    # effect size\n",
        "    std_dev = np.std(X_associations + Y_associations)\n",
        "    effect_size = test_statistic / std_dev if std_dev > 0 else 0\n",
        "\n",
        "    all_targets = X_valid + Y_valid\n",
        "    size_X = len(X_valid)\n",
        "    n_samples = 1000\n",
        "    permutation_scores = []\n",
        "\n",
        "    for _ in range(n_samples):\n",
        "        np.random.shuffle(all_targets)\n",
        "        X_i = all_targets[:size_X]\n",
        "        Y_i = all_targets[size_X:]\n",
        "        X_i_associations = [association(x, A_valid, B_valid) for x in X_i]\n",
        "        Y_i_associations = [association(y, A_valid, B_valid) for y in Y_i]\n",
        "        permutation_scores.append(np.mean(X_i_associations) - np.mean(Y_i_associations))\n",
        "\n",
        "    # p-value\n",
        "    p_value = np.mean([score >= test_statistic for score in permutation_scores])\n",
        "\n",
        "    return effect_size, p_value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1m105zpP_1QI"
      },
      "source": [
        "### WEAT test sets for selected biases - Gender and Racial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4jVhs8mrUNoN"
      },
      "outputs": [],
      "source": [
        "# Define WEAT test sets for gender\n",
        "weat_gender = {\n",
        "    'target': {\n",
        "        'X': ['man', 'boy', 'father', 'male', 'gentleman', 'son', 'he', 'his', 'him'],\n",
        "        'Y': ['woman', 'girl', 'mother', 'female', 'lady', 'daughter', 'she', 'hers', 'her']\n",
        "    },\n",
        "    'attribute': {\n",
        "        'A': ['math', 'algebra', 'geometry', 'calculus', 'equations', 'computation', 'numbers', 'addition'],\n",
        "        'B': ['literature', 'arts', 'poetry', 'dance', 'literature', 'novel', 'symphony', 'drama']\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_wn3qvrUQav"
      },
      "outputs": [],
      "source": [
        "# Define WEAT test sets for race\n",
        "weat_race = {\n",
        "    'target': {\n",
        "        'X': ['european', 'caucasian', 'white'],\n",
        "        'Y': ['african', 'black']\n",
        "    },\n",
        "    'attribute': {\n",
        "        'A': ['pleasant', 'nice', 'good', 'wonderful', 'excellent', 'happy', 'joy'],\n",
        "        'B': ['unpleasant', 'bad', 'terrible', 'horrible', 'awful', 'sad', 'anger']\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBRYl1Lg_hrX"
      },
      "outputs": [],
      "source": [
        "gender_targets = {\n",
        "    'male_terms': ['male', 'man', 'boy', 'brother', 'he', 'father', 'son', 'uncle'],\n",
        "    'female_terms': ['female', 'woman', 'girl', 'sister', 'she', 'mother', 'daughter', 'aunt']\n",
        "}\n",
        "\n",
        "gender_attributes = {\n",
        "    'career': ['executive', 'management', 'professional', 'salary', 'office', 'boss', 'business'],\n",
        "    'family': ['home', 'parents', 'children', 'family', 'marriage', 'wedding', 'kitchen']\n",
        "}\n",
        "\n",
        "racial_targets = {\n",
        "    'european_american': ['Adam', 'Harry', 'Roger', 'Alan', 'Ryan', 'Neil', 'Brad'],\n",
        "    'african_american': ['Darnell', 'Hakim', 'Jermaine', 'Tyrone', 'Leroy', 'Rasheed', 'DeShawn']\n",
        "}\n",
        "\n",
        "racial_attributes = {\n",
        "    'pleasant': ['joy', 'love', 'peace', 'wonderful', 'pleasure', 'happy', 'laughter'],\n",
        "    'unpleasant': ['agony', 'terrible', 'horrible', 'nasty', 'evil', 'war', 'awful']\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8snpHd66wuBI"
      },
      "source": [
        "### Running the test\n",
        "\n",
        "We call the WEAT test function and run bias test for Gender and Race separately. We evaluate the bias for these two features on the pre-trained embeddings of GLoVe and Word2vec."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMOmirPiUWhg",
        "outputId": "c13d8fe3-3369-4364-a551-9b5149f5eb9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running WEAT tests on Word2Vec:\n",
            "Gender bias (Career vs Family): Effect size = 1.2232, p-value = 0.0020\n",
            "Racial bias (Pleasant vs Unpleasant): Effect size = 1.5022, p-value = 0.1070\n",
            "\n",
            "Running WEAT tests on GloVe:\n",
            "Gender bias (Career vs Family): Effect size = 0.7009, p-value = 0.0720\n",
            "Racial bias (Pleasant vs Unpleasant): Effect size = 0.0913, p-value = 0.6170\n"
          ]
        }
      ],
      "source": [
        "def run_weat_tests(embeddings, name):\n",
        "    print(f\"\\nRunning WEAT tests on {name}:\")\n",
        "\n",
        "    # Gender test\n",
        "    effect_size, p_value = weat_test(\n",
        "        weat_gender['target']['X'],\n",
        "        weat_gender['target']['Y'],\n",
        "        weat_gender['attribute']['A'],\n",
        "        weat_gender['attribute']['B'],\n",
        "        embeddings\n",
        "    )\n",
        "    print(f\"Gender bias (Career vs Family): Effect size = {effect_size:.4f}, p-value = {p_value:.4f}\")\n",
        "\n",
        "    # Race test\n",
        "    effect_size, p_value = weat_test(\n",
        "        weat_race['target']['X'],\n",
        "        weat_race['target']['Y'],\n",
        "        weat_race['attribute']['A'],\n",
        "        weat_race['attribute']['B'],\n",
        "        embeddings\n",
        "    )\n",
        "    print(f\"Racial bias (Pleasant vs Unpleasant): Effect size = {effect_size:.4f}, p-value = {p_value:.4f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_weat_tests(word2vec, 'Word2Vec')\n",
        "    run_weat_tests(glove, 'GloVe')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9C0n0tUidcB"
      },
      "source": [
        "## Direct bias\n",
        "\n",
        "We measure direct bias in word embeddings by projecting specific words onto gender direction here. This approach is based on the paper [4] (Bolukbasi et al.) where we calculate gender direction and normalize it, select few words to evaluate the bias for each category.\n",
        "\n",
        "A projection is defined as the dot product with the calculated gender direction.\n",
        "\n",
        "**How direct bias works** ? We define a custom bias direction in the vector space and measure how strongly the defined words project onto this direction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j31VYyFY54jh"
      },
      "source": [
        "### Gender Bias\n",
        "\n",
        "We use direct bias to first define a gender direction using word pairs, calculate a gender direction and then calculate bias scores by averaging the gender direction [9][10]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QMj3E5f0g-DM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "def measure_direct_bias(embeddings, name):\n",
        "    # define gender direction using word pairs\n",
        "    gender_pairs = [\n",
        "        ('he', 'she'),\n",
        "        ('man', 'woman'),\n",
        "        ('father', 'mother'),\n",
        "        ('boy', 'girl'),\n",
        "        ('son', 'daughter'),\n",
        "        ('husband', 'wife'),\n",
        "        ('gentleman', 'lady'),\n",
        "        ('uncle', 'aunt')\n",
        "    ]\n",
        "\n",
        "    # calculate gender direction\n",
        "    gender_vectors = []\n",
        "    for male, female in gender_pairs:\n",
        "        male_vec = get_word_vector(male, embeddings)\n",
        "        female_vec = get_word_vector(female, embeddings)\n",
        "\n",
        "        if male_vec is not None and female_vec is not None:\n",
        "            male_vec = male_vec / np.linalg.norm(male_vec) # normalize vectors\n",
        "            female_vec = female_vec / np.linalg.norm(female_vec)\n",
        "            gender_vectors.append(male_vec - female_vec)\n",
        "\n",
        "    if not gender_vectors:\n",
        "        print(\"Could not calculate gender direction: no valid gender pairs found\")\n",
        "        return None\n",
        "\n",
        "    # average gender direction\n",
        "    gender_direction = np.mean(gender_vectors, axis=0)\n",
        "    gender_direction = gender_direction / np.linalg.norm(gender_direction)\n",
        "\n",
        "    # selecting few words to evaluate for bias\n",
        "    profession_words = [\n",
        "        'doctor', 'nurse', 'engineer', 'teacher', 'programmer', 'artist',\n",
        "        'scientist', 'writer', 'ceo', 'assistant', 'manager', 'secretary',\n",
        "        'carpenter', 'chef', 'designer', 'accountant', 'lawyer', 'banker',\n",
        "        'receptionist', 'journalist', 'professor', 'researcher', 'pilot', 'dancer'\n",
        "    ]\n",
        "\n",
        "    # calculate direct bias\n",
        "    results = []\n",
        "    for word in profession_words:\n",
        "        vec = get_word_vector(word, embeddings)\n",
        "        if vec is not None:\n",
        "            vec = vec / np.linalg.norm(vec)\n",
        "            bias = np.dot(vec, gender_direction) # project onto gender direction\n",
        "            results.append({'word': word, 'bias': bias})\n",
        "\n",
        "    if not results:\n",
        "        print(\"No valid profession words found for direct bias calculation\")\n",
        "        return None\n",
        "\n",
        "    df = pd.DataFrame(results)\n",
        "    df = df.sort_values(by='bias', ascending=False)\n",
        "\n",
        "    print(\"\\nMost male-associated professions:\") # output most biased words\n",
        "    for _, row in df.head(5).iterrows():\n",
        "        print(f\"  {row['word']}: {row['bias']:.4f}\")\n",
        "\n",
        "    print(\"\\nMost female-associated professions:\")\n",
        "    for _, row in df.tail(5).iloc[::-1].iterrows():\n",
        "        print(f\"  {row['word']}: {row['bias']:.4f}\")\n",
        "\n",
        "    avg_abs_bias = df['bias'].abs().mean()\n",
        "    print(f\"\\nAverage absolute direct bias: {avg_abs_bias:.4f}\")\n",
        "\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    colors = ['blue' if x > 0 else 'red' for x in df['bias']]\n",
        "    bars = plt.bar(df['word'], df['bias'], color=colors)\n",
        "    plt.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
        "    plt.xlabel('Profession')\n",
        "    plt.ylabel('Direct Bias (projection onto gender direction)')\n",
        "    plt.title(f'Direct Gender Bias in {name} Embeddings')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.legend([plt.Rectangle((0,0),1,1,color='blue'),\n",
        "                plt.Rectangle((0,0),1,1,color='red')],\n",
        "               ['Male-associated', 'Female-associated'])\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'direct_bias_{name}.png')\n",
        "    plt.close()\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G35ykyvokdXR",
        "outputId": "58125ac3-3f56-4222-dd22-3ec215d5b736"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Most male-associated professions:\n",
            "  engineer: 0.2168\n",
            "  programmer: 0.1506\n",
            "  banker: 0.1381\n",
            "  pilot: 0.1376\n",
            "  ceo: 0.1205\n",
            "\n",
            "Most female-associated professions:\n",
            "  nurse: -0.2720\n",
            "  receptionist: -0.2309\n",
            "  dancer: -0.1845\n",
            "  researcher: -0.0962\n",
            "  teacher: -0.0705\n",
            "\n",
            "Average absolute direct bias: 0.0918\n",
            "\n",
            "Most male-associated professions:\n",
            "  carpenter: 0.2207\n",
            "  engineer: 0.1882\n",
            "  ceo: 0.0723\n",
            "  banker: 0.0652\n",
            "  manager: 0.0513\n",
            "\n",
            "Most female-associated professions:\n",
            "  nurse: -0.3150\n",
            "  receptionist: -0.2902\n",
            "  dancer: -0.2148\n",
            "  teacher: -0.1628\n",
            "  designer: -0.0722\n",
            "\n",
            "Average absolute direct bias: 0.0887\n",
            "\n",
            "Correlation between GloVe and Word2Vec direct bias: 0.9006\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    glove_bias = measure_direct_bias(glove, 'GloVe')\n",
        "    word2vec_bias = measure_direct_bias(word2vec, 'Word2Vec')\n",
        "\n",
        "    if glove_bias is not None and word2vec_bias is not None:\n",
        "        merged = pd.merge(\n",
        "            glove_bias.rename(columns={'bias': 'glove_bias'}),\n",
        "            word2vec_bias.rename(columns={'bias': 'word2vec_bias'}),\n",
        "            on='word'\n",
        "        )\n",
        "\n",
        "        correlation = np.corrcoef(merged['glove_bias'], merged['word2vec_bias'])[0, 1]\n",
        "        print(f\"\\nCorrelation between GloVe and Word2Vec direct bias: {correlation:.4f}\")\n",
        "\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        plt.scatter(merged['glove_bias'], merged['word2vec_bias'], alpha=0.7)\n",
        "\n",
        "        min_val = min(merged['glove_bias'].min(), merged['word2vec_bias'].min())\n",
        "        max_val = max(merged['glove_bias'].max(), merged['word2vec_bias'].max())\n",
        "        plt.plot([min_val, max_val], [min_val, max_val], 'k--', alpha=0.5)\n",
        "\n",
        "        for _, row in merged.iterrows():\n",
        "            plt.annotate(row['word'],\n",
        "                         (row['glove_bias'], row['word2vec_bias']),\n",
        "                         xytext=(5, 5), textcoords='offset points')\n",
        "\n",
        "        plt.xlabel('GloVe Direct Bias')\n",
        "        plt.ylabel('Word2Vec Direct Bias')\n",
        "        plt.title('Comparison of Direct Gender Bias Between Embeddings')\n",
        "        plt.axhline(y=0, color='gray', linestyle='-', alpha=0.3)\n",
        "        plt.axvline(x=0, color='gray', linestyle='-', alpha=0.3)\n",
        "        plt.grid(alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('direct_bias_comparison.png')\n",
        "        plt.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElmWMU1157kI"
      },
      "source": [
        "### Racial Bias\n",
        "\n",
        "We use Direct bias to first create a racial direction and then normalize the direction vectors to determine the projection scores [11]. Positive scores indicate association with one racial group while negative scores indicate association with other racial group."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ihUDEuOtmI_q"
      },
      "outputs": [],
      "source": [
        "def measure_racial_direct_bias(embeddings, name):\n",
        "    print(f\"\\nMeasuring direct racial bias in {name} embeddings:\")\n",
        "    # define racial direction using pairs\n",
        "    race_pairs = [\n",
        "        ('white', 'black'),\n",
        "        ('caucasian', 'african'),\n",
        "        ('european', 'african-american'),\n",
        "        ('white', 'asian'),\n",
        "        ('caucasian', 'hispanic'),\n",
        "        ('european', 'latino')\n",
        "    ]\n",
        "\n",
        "    race_vectors = [] # calculate racial direction\n",
        "\n",
        "    print(\"Building racial direction vector...\")\n",
        "    for race1, race2 in race_pairs:\n",
        "        race1_vec = get_word_vector(race1, embeddings)\n",
        "        race2_vec = get_word_vector(race2, embeddings)\n",
        "\n",
        "        if race1_vec is not None and race2_vec is not None:\n",
        "            race1_vec = race1_vec / np.linalg.norm(race1_vec) # normalize vectors\n",
        "            race2_vec = race2_vec / np.linalg.norm(race2_vec)\n",
        "            race_vectors.append(race1_vec - race2_vec)\n",
        "            print(f\"  Added direction: {race1} - {race2}\")\n",
        "\n",
        "    if not race_vectors:\n",
        "        print(\"Could not calculate racial direction: no valid race pairs found\")\n",
        "        return None\n",
        "\n",
        "    racial_direction = np.mean(race_vectors, axis=0)\n",
        "    racial_direction = racial_direction / np.linalg.norm(racial_direction)\n",
        "\n",
        "    eval_words = [\n",
        "        'intelligent', 'smart', 'educated', 'skilled', 'capable', 'competent',\n",
        "        'hardworking', 'ambitious', 'successful', 'wealthy', 'rich',\n",
        "        'poor', 'criminal', 'dangerous', 'violent', 'lazy', 'uneducated', 'welfare',\n",
        "        'professional', 'leader', 'doctor', 'lawyer', 'scientist', 'engineer',\n",
        "        'teacher', 'nurse', 'athlete', 'musician', 'artist', 'journalist',\n",
        "        'police', 'chef', 'worker', 'janitor', 'assistant', 'manager',\n",
        "        'trustworthy', 'honest', 'religious', 'family', 'community', 'urban',\n",
        "        'rural', 'friendly', 'aggressive', 'loud', 'quiet', 'disciplined'\n",
        "    ]\n",
        "\n",
        "    results = []\n",
        "    for word in eval_words:\n",
        "        vec = get_word_vector(word, embeddings)\n",
        "        if vec is not None:\n",
        "            vec = vec / np.linalg.norm(vec)\n",
        "            bias = np.dot(vec, racial_direction)\n",
        "            results.append({'word': word, 'bias': bias})\n",
        "\n",
        "    if not results:\n",
        "        print(\"No valid evaluation words found for direct bias calculation\")\n",
        "        return None\n",
        "\n",
        "    df = pd.DataFrame(results)\n",
        "    df = df.sort_values(by='bias', ascending=False)\n",
        "\n",
        "    print(\"\\nWords most associated with White/European (positive projection):\")\n",
        "    for _, row in df.head(10).iterrows():\n",
        "        print(f\"  {row['word']}: {row['bias']:.4f}\")\n",
        "\n",
        "    print(\"\\nWords most associated with Black/African American groups (negative projection):\")\n",
        "    for _, row in df.tail(10).iloc[::-1].iterrows():\n",
        "        print(f\"  {row['word']}: {row['bias']:.4f}\")\n",
        "\n",
        "    avg_abs_bias = df['bias'].abs().mean()\n",
        "    print(f\"\\nAverage absolute direct racial bias: {avg_abs_bias:.4f}\")\n",
        "\n",
        "    # categorize words for visualization\n",
        "    categories = {\n",
        "        'Positive Attributes': ['intelligent', 'smart', 'educated', 'skilled', 'capable',\n",
        "                                'competent', 'hardworking', 'ambitious', 'successful',\n",
        "                                'wealthy', 'rich'],\n",
        "        'Negative Attributes': ['poor', 'criminal', 'dangerous', 'violent', 'lazy',\n",
        "                               'uneducated', 'welfare'],\n",
        "        'Professions': ['professional', 'leader', 'doctor', 'lawyer', 'scientist',\n",
        "                        'engineer', 'teacher', 'nurse', 'athlete', 'musician', 'artist',\n",
        "                        'journalist', 'police', 'chef', 'worker', 'janitor', 'assistant',\n",
        "                        'manager'],\n",
        "        'Personality': ['trustworthy', 'honest', 'religious', 'family', 'community',\n",
        "                        'urban', 'rural', 'friendly', 'aggressive', 'loud', 'quiet',\n",
        "                        'disciplined']\n",
        "    }\n",
        "\n",
        "    df['category'] = 'Other'\n",
        "    for category, words in categories.items():\n",
        "        df.loc[df['word'].isin(words), 'category'] = category\n",
        "\n",
        "    plt.figure(figsize=(14, 10))\n",
        "    sns.set_palette(\"Set1\") # plots bias values by category\n",
        "    ax = sns.barplot(x='word', y='bias', hue='category', data=df)\n",
        "    plt.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
        "    plt.xlabel('Word')\n",
        "    plt.ylabel('Direct Racial Bias')\n",
        "    plt.title(f'Direct Racial Bias in {name} Embeddings')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'direct_racial_bias_{name}.png')\n",
        "    plt.close()\n",
        "\n",
        "    # plots average bias by category\n",
        "    category_avg = df.groupby('category')['bias'].mean().reset_index()\n",
        "    category_std = df.groupby('category')['bias'].std().reset_index()\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    bars = plt.bar(category_avg['category'], category_avg['bias'])\n",
        "\n",
        "    plt.errorbar(x=category_avg['category'], y=category_avg['bias'],\n",
        "                 yerr=category_std['bias'], fmt='none', capsize=5, color='black')\n",
        "\n",
        "    for i, bar in enumerate(bars):\n",
        "        if category_avg['bias'].iloc[i] > 0:\n",
        "            bar.set_color('darkorange')\n",
        "        else:\n",
        "            bar.set_color('steelblue')\n",
        "\n",
        "    plt.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
        "    plt.title(f'Average Racial Bias by Category in {name} Embeddings')\n",
        "    plt.ylabel('Average Bias (+ = White/European Association)')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'racial_bias_by_category_{name}.png')\n",
        "    plt.close()\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "rEEYeFxqnEwH"
      },
      "outputs": [],
      "source": [
        "def compare_direct_racial_bias(glove_bias, word2vec_bias):\n",
        "    if glove_bias is None or word2vec_bias is None:\n",
        "        print(\"Cannot compare biases: one or both bias measurements are missing\")\n",
        "        return\n",
        "\n",
        "    merged = pd.merge(\n",
        "        glove_bias[['word', 'bias', 'category']].rename(columns={'bias': 'glove_bias'}),\n",
        "        word2vec_bias[['word', 'bias']].rename(columns={'bias': 'word2vec_bias'}),\n",
        "        on='word', how='inner'\n",
        "    )\n",
        "\n",
        "    # calculate correlation\n",
        "    correlation = np.corrcoef(merged['glove_bias'], merged['word2vec_bias'])[0, 1]\n",
        "    print(f\"\\nCorrelation between GloVe and Word2Vec direct racial bias: {correlation:.4f}\")\n",
        "\n",
        "    plt.figure(figsize=(12, 10))\n",
        "\n",
        "    # plot by category\n",
        "    categories = merged['category'].unique()\n",
        "    colors = sns.color_palette(\"Set1\", len(categories))\n",
        "\n",
        "    for i, category in enumerate(categories):\n",
        "        category_data = merged[merged['category'] == category]\n",
        "        plt.scatter(\n",
        "            category_data['glove_bias'],\n",
        "            category_data['word2vec_bias'],\n",
        "            label=category,\n",
        "            color=colors[i],\n",
        "            alpha=0.7,\n",
        "            s=70\n",
        "        )\n",
        "\n",
        "    m, b = np.polyfit(merged['glove_bias'], merged['word2vec_bias'], 1)\n",
        "    x_range = np.array([merged['glove_bias'].min(), merged['glove_bias'].max()])\n",
        "    plt.plot(x_range, m*x_range + b, 'k--', alpha=0.7, linewidth=2)\n",
        "\n",
        "    min_val = min(merged['glove_bias'].min(), merged['word2vec_bias'].min())\n",
        "    max_val = max(merged['glove_bias'].max(), merged['word2vec_bias'].max())\n",
        "    plt.plot([min_val, max_val], [min_val, max_val], 'k-', alpha=0.3)\n",
        "\n",
        "    for i, row in merged.iterrows():\n",
        "        if (abs(row['glove_bias']) > 0.15 or\n",
        "            abs(row['word2vec_bias']) > 0.15 or\n",
        "            abs(row['glove_bias'] - row['word2vec_bias']) > 0.1):\n",
        "            plt.annotate(row['word'],\n",
        "                        (row['glove_bias'], row['word2vec_bias']),\n",
        "                        xytext=(5, 5), textcoords='offset points',\n",
        "                        fontsize=9)\n",
        "\n",
        "    plt.xlabel('GloVe Direct Racial Bias')\n",
        "    plt.ylabel('Word2Vec Direct Racial Bias')\n",
        "    plt.title('Comparison of Direct Racial Bias Between Embeddings')\n",
        "    plt.axhline(y=0, color='gray', linestyle='-', alpha=0.3)\n",
        "    plt.axvline(x=0, color='gray', linestyle='-', alpha=0.3)\n",
        "    plt.grid(alpha=0.3)\n",
        "    plt.legend(title=\"Category\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('direct_racial_bias_comparison.png')\n",
        "    plt.close()\n",
        "\n",
        "    # Finding which embedding shows stronger bias for each word\n",
        "    merged['abs_glove'] = np.abs(merged['glove_bias'])\n",
        "    merged['abs_word2vec'] = np.abs(merged['word2vec_bias'])\n",
        "    merged['stronger_bias'] = np.where(\n",
        "        merged['abs_glove'] > merged['abs_word2vec'],\n",
        "        'GloVe',\n",
        "        'Word2Vec'\n",
        "    )\n",
        "\n",
        "    # count by category\n",
        "    bias_by_category = merged.groupby(['category', 'stronger_bias']).size().unstack()\n",
        "    print(\"\\nWords with stronger bias by category and embedding type:\")\n",
        "    print(bias_by_category)\n",
        "\n",
        "    # calculate agreement in bias direction\n",
        "    merged['same_direction'] = np.sign(merged['glove_bias']) == np.sign(merged['word2vec_bias'])\n",
        "    agreement = merged['same_direction'].mean() * 100\n",
        "    print(f\"\\nPercent of words with same bias direction in both embeddings: {agreement:.1f}%\")\n",
        "\n",
        "    # calculate agreements by category\n",
        "    agreement_by_category = merged.groupby('category')['same_direction'].mean() * 100\n",
        "    print(\"\\nAgreement in bias direction by category:\")\n",
        "    for category, agreement in agreement_by_category.items():\n",
        "        print(f\"  {category}: {agreement:.1f}%\")\n",
        "\n",
        "    return merged"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ae9B5rdnR1B",
        "outputId": "efd7fc38-a774-4214-eba3-f52ccaa82cbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Measuring direct racial bias in GloVe embeddings:\n",
            "Building racial direction vector...\n",
            "  Added direction: white - black\n",
            "  Added direction: caucasian - african\n",
            "  Added direction: european - african-american\n",
            "  Added direction: white - asian\n",
            "  Added direction: caucasian - hispanic\n",
            "  Added direction: european - latino\n",
            "\n",
            "Words most associated with White/European (positive projection):\n",
            "  friendly: 0.0938\n",
            "  dangerous: 0.0455\n",
            "  aggressive: 0.0455\n",
            "  quiet: 0.0310\n",
            "  manager: 0.0231\n",
            "  leader: 0.0144\n",
            "  loud: 0.0081\n",
            "  engineer: 0.0069\n",
            "  lazy: 0.0057\n",
            "  criminal: 0.0006\n",
            "\n",
            "Words most associated with Black/African American groups (negative projection):\n",
            "  community: -0.2328\n",
            "  urban: -0.2295\n",
            "  uneducated: -0.1894\n",
            "  rural: -0.1695\n",
            "  musician: -0.1668\n",
            "  poor: -0.1535\n",
            "  skilled: -0.1443\n",
            "  hardworking: -0.1357\n",
            "  successful: -0.1136\n",
            "  artist: -0.1135\n",
            "\n",
            "Average absolute direct racial bias: 0.0724\n",
            "\n",
            "Measuring direct racial bias in Word2Vec embeddings:\n",
            "Building racial direction vector...\n",
            "  Added direction: white - black\n",
            "  Added direction: caucasian - african\n",
            "  Added direction: white - asian\n",
            "  Added direction: caucasian - hispanic\n",
            "  Added direction: european - latino\n",
            "\n",
            "Words most associated with White/European (positive projection):\n",
            "  capable: 0.1206\n",
            "  quiet: 0.1029\n",
            "  family: 0.1020\n",
            "  trustworthy: 0.0948\n",
            "  lawyer: 0.0923\n",
            "  dangerous: 0.0849\n",
            "  police: 0.0819\n",
            "  competent: 0.0781\n",
            "  friendly: 0.0744\n",
            "  loud: 0.0729\n",
            "\n",
            "Words most associated with Black/African American groups (negative projection):\n",
            "  community: -0.1268\n",
            "  urban: -0.0879\n",
            "  artist: -0.0853\n",
            "  uneducated: -0.0540\n",
            "  honest: -0.0534\n",
            "  poor: -0.0487\n",
            "  ambitious: -0.0443\n",
            "  musician: -0.0412\n",
            "  assistant: -0.0316\n",
            "  welfare: -0.0305\n",
            "\n",
            "Average absolute direct racial bias: 0.0475\n",
            "\n",
            "Correlation between GloVe and Word2Vec direct racial bias: 0.5996\n",
            "\n",
            "Words with stronger bias by category and embedding type:\n",
            "stronger_bias        GloVe  Word2Vec\n",
            "category                            \n",
            "Negative Attributes      4         3\n",
            "Personality              8         4\n",
            "Positive Attributes      7         4\n",
            "Professions             11         7\n",
            "\n",
            "Percent of words with same bias direction in both embeddings: 56.2%\n",
            "\n",
            "Agreement in bias direction by category:\n",
            "  Negative Attributes: 100.0%\n",
            "  Personality: 58.3%\n",
            "  Positive Attributes: 9.1%\n",
            "  Professions: 66.7%\n",
            "\n",
            "Racial bias evaluation completed successfully!\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "  glove_bias = measure_racial_direct_bias(glove, 'GloVe')\n",
        "  word2vec_bias = measure_racial_direct_bias(word2vec, 'Word2Vec')\n",
        "  comparison = compare_direct_racial_bias(glove_bias, word2vec_bias)\n",
        "  print(\"\\nRacial bias evaluation completed successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SX-W-5e1l5c"
      },
      "source": [
        "## t-SNE\n",
        "\n",
        "*  t-distributed Stochastic Neighbor Embedding, is an algorithm used for visualizing high-dimensional data by reducing it to two (in this case) dimensions while preserving the relationships between data points.\n",
        "*   We perform t-SNE to understand the clustering patterns between words that indicate bias, showing how certain words cluster with gender-biased/racial-biased professions or attributes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UwKSbZ2pAMab"
      },
      "outputs": [],
      "source": [
        "def cluster_analysis_tsne(embeddings, target_words, title, filename):\n",
        "    word_vectors = []\n",
        "    labels = []\n",
        "    categories = []\n",
        "\n",
        "    for category, words in target_words.items():\n",
        "        for word in words:\n",
        "            vector = get_word_vector(word, embeddings)\n",
        "            if vector is not None:\n",
        "                word_vectors.append(vector)\n",
        "                labels.append(word)\n",
        "                categories.append(category)\n",
        "\n",
        "    if len(word_vectors) < 5:\n",
        "        print(f\"Not enough words found in embeddings for {title}\")\n",
        "        return\n",
        "\n",
        "    # t-SNE\n",
        "    word_vectors = np.array(word_vectors)\n",
        "    tsne = TSNE(n_components=2, random_state=42, perplexity=min(30, len(word_vectors)-1))\n",
        "    reduced_vectors = tsne.fit_transform(word_vectors)\n",
        "\n",
        "    # create DataFrame for plotting\n",
        "    df = pd.DataFrame({\n",
        "        'x': reduced_vectors[:, 0],\n",
        "        'y': reduced_vectors[:, 1],\n",
        "        'word': labels,\n",
        "        'category': categories\n",
        "    })\n",
        "\n",
        "    plt.figure(figsize=(12, 10))\n",
        "\n",
        "    palette = sns.color_palette(\"husl\", len(target_words))\n",
        "    categories_list = list(target_words.keys())\n",
        "    color_dict = {cat: palette[i] for i, cat in enumerate(categories_list)}\n",
        "\n",
        "    for category in categories_list:\n",
        "        category_df = df[df['category'] == category]\n",
        "        plt.scatter(category_df['x'], category_df['y'], label=category,\n",
        "                   color=color_dict[category], alpha=0.7)\n",
        "\n",
        "    for i, row in df.iterrows():\n",
        "        plt.annotate(row['word'], (row['x'], row['y']), fontsize=9,\n",
        "                    xytext=(5, 5), textcoords='offset points')\n",
        "\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(filename)\n",
        "    plt.close()\n",
        "\n",
        "# define word sets for cluster analysis\n",
        "gender_occupation_words = {\n",
        "    'male': ['man', 'boy', 'father', 'brother', 'son', 'husband', 'uncle', 'grandfather'],\n",
        "    'female': ['woman', 'girl', 'mother', 'sister', 'daughter', 'wife', 'aunt', 'grandmother'],\n",
        "    'stem': ['scientist', 'engineer', 'mathematician', 'programmer', 'researcher', 'doctor', 'physicist', 'chemist'],\n",
        "    'humanities': ['artist', 'writer', 'poet', 'dancer', 'singer', 'actor', 'designer', 'philosopher'],\n",
        "    'leadership': ['ceo', 'boss', 'executive', 'director', 'manager', 'supervisor', 'leader', 'president']\n",
        "}\n",
        "\n",
        "race_attribute_words = {\n",
        "    'white': ['european', 'caucasian', 'white', 'western', 'anglo'],\n",
        "    'black': ['african', 'black', 'afro'],\n",
        "    'asian': ['asian', 'chinese', 'japanese', 'korean', 'eastern'],\n",
        "    'positive': ['good', 'nice', 'excellent', 'positive', 'fortunate', 'correct', 'superior'],\n",
        "    'negative': ['bad', 'awful', 'terrible', 'negative', 'unfortunate', 'wrong', 'inferior']\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RZJd4bB2k86",
        "outputId": "83fb34c3-f78c-4cac-82b6-48cfb8b095bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running t-SNE cluster analysis on Word2Vec:\n",
            "\n",
            "Running t-SNE cluster analysis on GLoVe:\n"
          ]
        }
      ],
      "source": [
        "def run_cluster_analysis(embeddings, name):\n",
        "    print(f\"\\nRunning t-SNE cluster analysis on {name}:\")\n",
        "\n",
        "    # Gender-occupation analysis\n",
        "    cluster_analysis_tsne(\n",
        "        embeddings,\n",
        "        gender_occupation_words,\n",
        "        f'Gender, Occupation & Leadership Clusters in {name}',\n",
        "        f'tsne_gender_occupation_{name}.png'\n",
        "    )\n",
        "\n",
        "    # Race-attribute analysis\n",
        "    cluster_analysis_tsne(\n",
        "        embeddings,\n",
        "        race_attribute_words,\n",
        "        f'Race & Attribute Clusters in {name}',\n",
        "        f'tsne_race_attribute_{name}.png'\n",
        "    )\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "  run_cluster_analysis(word2vec, 'Word2Vec')\n",
        "  run_cluster_analysis(glove, 'GLoVe')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GtThbJ44-Hz"
      },
      "source": [
        "## Cross Embedding Comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGkZQvxA7fui"
      },
      "source": [
        "#### Gender Bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tu8V_OyIfRFe",
        "outputId": "48882af4-dfd3-413b-efbe-5079d2cdcab7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Correlation between GloVe and Word2Vec gender biases: 0.9506\n",
            "\n",
            "Most male-biased professions:\n",
            "\n",
            "GloVe:\n",
            "  engineer: 0.1175\n",
            "  programmer: 0.0816\n",
            "  ceo: 0.0653\n",
            "\n",
            "Word2Vec:\n",
            "  engineer: 0.0936\n",
            "  ceo: 0.0359\n",
            "  manager: 0.0255\n",
            "\n",
            "Most female-biased professions:\n",
            "\n",
            "GloVe:\n",
            "  nurse: -0.1474\n",
            "  teacher: -0.0382\n",
            "  writer: -0.0026\n",
            "\n",
            "Word2Vec:\n",
            "  nurse: -0.1566\n",
            "  teacher: -0.0809\n",
            "  artist: -0.0248\n",
            "\n",
            "Average absolute gender bias:\n",
            "GloVe: 0.0502\n",
            "Word2Vec: 0.0421\n",
            "\n",
            "Which embedding shows stronger bias:\n",
            "GloVe: 5 professions\n",
            "Word2Vec: 4 professions\n",
            "Equal: 3 professions\n"
          ]
        }
      ],
      "source": [
        "def compare_embeddings(glove_embeddings, word2vec_embeddings):\n",
        "    gender_pairs = [\n",
        "        ('he', 'she'),\n",
        "        ('man', 'woman'),\n",
        "        ('father', 'mother'),\n",
        "        ('boy', 'girl'),\n",
        "        ('son', 'daughter'),\n",
        "        ('husband', 'wife'),\n",
        "        ('gentleman', 'lady'),\n",
        "        ('uncle', 'aunt')\n",
        "    ]\n",
        "\n",
        "    profession_words = [\n",
        "        'doctor', 'nurse', 'engineer', 'teacher', 'programmer', 'artist',\n",
        "        'scientist', 'writer', 'ceo', 'assistant', 'manager', 'secretary'\n",
        "    ]\n",
        "\n",
        "    # gender bias for each profession across embedding types\n",
        "    results = []\n",
        "\n",
        "    for profession in profession_words:\n",
        "        glove_gender_biases = []\n",
        "        word2vec_gender_biases = []\n",
        "\n",
        "        for male, female in gender_pairs:\n",
        "            prof_vec_glove = get_word_vector(profession, glove_embeddings)\n",
        "            male_vec_glove = get_word_vector(male, glove_embeddings)\n",
        "            female_vec_glove = get_word_vector(female, glove_embeddings)\n",
        "\n",
        "            if prof_vec_glove is not None and male_vec_glove is not None and female_vec_glove is not None:\n",
        "                male_sim_glove = cosine_sim(prof_vec_glove, male_vec_glove)\n",
        "                female_sim_glove = cosine_sim(prof_vec_glove, female_vec_glove)\n",
        "                glove_gender_biases.append(male_sim_glove - female_sim_glove)\n",
        "\n",
        "            prof_vec_w2v = get_word_vector(profession, word2vec_embeddings)\n",
        "            male_vec_w2v = get_word_vector(male, word2vec_embeddings)\n",
        "            female_vec_w2v = get_word_vector(female, word2vec_embeddings)\n",
        "\n",
        "            if prof_vec_w2v is not None and male_vec_w2v is not None and female_vec_w2v is not None:\n",
        "                male_sim_w2v = cosine_sim(prof_vec_w2v, male_vec_w2v)\n",
        "                female_sim_w2v = cosine_sim(prof_vec_w2v, female_vec_w2v)\n",
        "                word2vec_gender_biases.append(male_sim_w2v - female_sim_w2v)\n",
        "\n",
        "        if glove_gender_biases and word2vec_gender_biases:\n",
        "            results.append({\n",
        "                'profession': profession,\n",
        "                'glove_bias': np.mean(glove_gender_biases),\n",
        "                'word2vec_bias': np.mean(word2vec_gender_biases)\n",
        "            })\n",
        "\n",
        "    if results:\n",
        "        df = pd.DataFrame(results)\n",
        "\n",
        "        plt.figure(figsize=(12, 8))\n",
        "\n",
        "        x = np.arange(len(df))\n",
        "        width = 0.35\n",
        "\n",
        "        plt.bar(x - width/2, df['glove_bias'], width, label='GloVe')\n",
        "        plt.bar(x + width/2, df['word2vec_bias'], width, label='Word2Vec')\n",
        "\n",
        "        plt.axhline(y=0, color='r', linestyle='--')\n",
        "        plt.xlabel('Profession')\n",
        "        plt.ylabel('Gender Bias (Male - Female Similarity)')\n",
        "        plt.title('Comparison of Gender Bias Across Embedding Types')\n",
        "        plt.xticks(x, df['profession'], rotation=45)\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('embedding_comparison.png')\n",
        "        plt.close()\n",
        "\n",
        "        correlation = np.corrcoef(df['glove_bias'], df['word2vec_bias'])[0, 1]\n",
        "        print(f\"Correlation between GloVe and Word2Vec gender biases: {correlation:.4f}\")\n",
        "\n",
        "        print(\"\\nMost male-biased professions:\")\n",
        "        for embed_type in ['glove_bias', 'word2vec_bias']:\n",
        "            top_male_biased = df.sort_values(by=embed_type, ascending=False).head(3)\n",
        "            embed_name = 'GloVe' if embed_type == 'glove_bias' else 'Word2Vec'\n",
        "            print(f\"\\n{embed_name}:\")\n",
        "            for _, row in top_male_biased.iterrows():\n",
        "                print(f\"  {row['profession']}: {row[embed_type]:.4f}\")\n",
        "\n",
        "        print(\"\\nMost female-biased professions:\")\n",
        "        for embed_type in ['glove_bias', 'word2vec_bias']:\n",
        "            top_female_biased = df.sort_values(by=embed_type, ascending=True).head(3)\n",
        "            embed_name = 'GloVe' if embed_type == 'glove_bias' else 'Word2Vec'\n",
        "            print(f\"\\n{embed_name}:\")\n",
        "            for _, row in top_female_biased.iterrows():\n",
        "                print(f\"  {row['profession']}: {row[embed_type]:.4f}\")\n",
        "\n",
        "        glove_avg_bias = df['glove_bias'].abs().mean()\n",
        "        word2vec_avg_bias = df['word2vec_bias'].abs().mean()\n",
        "        print(f\"\\nAverage absolute gender bias:\")\n",
        "        print(f\"GloVe: {glove_avg_bias:.4f}\")\n",
        "        print(f\"Word2Vec: {word2vec_avg_bias:.4f}\")\n",
        "\n",
        "        stronger_bias_counts = {'GloVe': 0, 'Word2Vec': 0, 'Equal': 0}\n",
        "        for _, row in df.iterrows():\n",
        "            glove_abs = abs(row['glove_bias'])\n",
        "            word2vec_abs = abs(row['word2vec_bias'])\n",
        "\n",
        "            if abs(glove_abs - word2vec_abs) < 0.01:\n",
        "                stronger_bias_counts['Equal'] += 1\n",
        "            elif glove_abs > word2vec_abs:\n",
        "                stronger_bias_counts['GloVe'] += 1\n",
        "            else:\n",
        "                stronger_bias_counts['Word2Vec'] += 1\n",
        "\n",
        "        print(\"\\nWhich embedding shows stronger bias:\")\n",
        "        for embed, count in stronger_bias_counts.items():\n",
        "            print(f\"{embed}: {count} professions\")\n",
        "\n",
        "    else:\n",
        "        print(\"No results to display. Check if words exist in both embeddings.\")\n",
        "\n",
        "    return df if results else None\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "  compare_embeddings(glove, word2vec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOUZ_N6H7jEW"
      },
      "source": [
        "#### Racial bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wud3ayMZ7kjr",
        "outputId": "daf6c9a3-c2f5-4f5c-a226-e14f1d9ed88b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Comparing racial bias across embedding types:\n",
            "Correlation between GloVe and Word2Vec racial biases: 0.4319\n",
            "\n",
            "Attributes most biased toward White/European people:\n",
            "\n",
            "GloVe:\n",
            "  dangerous: 0.0277\n",
            "  leader: 0.0088\n",
            "  engineer: 0.0042\n",
            "  lazy: 0.0034\n",
            "  criminal: 0.0004\n",
            "\n",
            "Word2Vec:\n",
            "  capable: 0.0638\n",
            "  trustworthy: 0.0501\n",
            "  lawyer: 0.0488\n",
            "  dangerous: 0.0449\n",
            "  competent: 0.0413\n",
            "\n",
            "Attributes most biased toward Black/African/Asian/Latino people:\n",
            "\n",
            "GloVe:\n",
            "  uneducated: -0.1154\n",
            "  poor: -0.0935\n",
            "  skilled: -0.0879\n",
            "  hardworking: -0.0827\n",
            "  musical: -0.0764\n",
            "\n",
            "Word2Vec:\n",
            "  artistic: -0.0299\n",
            "  uneducated: -0.0285\n",
            "  honest: -0.0283\n",
            "  poor: -0.0258\n",
            "  ambitious: -0.0234\n",
            "\n",
            "Average absolute racial bias:\n",
            "GloVe: 0.0392\n",
            "Word2Vec: 0.0245\n"
          ]
        }
      ],
      "source": [
        "def compare_racial_bias(glove_embeddings, word2vec_embeddings):\n",
        "    print(\"\\nComparing racial bias across embedding types:\")\n",
        "\n",
        "    race_pairs = [\n",
        "        ('white', 'black'),\n",
        "        ('caucasian', 'african'),\n",
        "        ('european', 'african-american'),\n",
        "        ('white', 'asian'),\n",
        "        ('caucasian', 'hispanic'),\n",
        "        ('european', 'latino')\n",
        "    ]\n",
        "\n",
        "    attribute_words = [\n",
        "        'intelligent', 'smart', 'educated', 'skilled', 'capable', 'competent',\n",
        "        'hardworking', 'ambitious', 'successful', 'wealthy', 'rich', 'poor',\n",
        "        'criminal', 'dangerous', 'violent', 'lazy', 'uneducated', 'welfare',\n",
        "        'professional', 'leader', 'doctor', 'lawyer', 'scientist', 'engineer',\n",
        "        'trustworthy', 'honest', 'religious', 'athletic', 'musical', 'artistic'\n",
        "    ]\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for attribute in attribute_words:\n",
        "        glove_race_biases = []\n",
        "        word2vec_race_biases = []\n",
        "\n",
        "        for race1, race2 in race_pairs:\n",
        "            attr_vec_glove = get_word_vector(attribute, glove_embeddings)\n",
        "            race1_vec_glove = get_word_vector(race1, glove_embeddings)\n",
        "            race2_vec_glove = get_word_vector(race2, glove_embeddings)\n",
        "\n",
        "            if attr_vec_glove is not None and race1_vec_glove is not None and race2_vec_glove is not None:\n",
        "                race1_sim_glove = cosine_sim(attr_vec_glove, race1_vec_glove)\n",
        "                race2_sim_glove = cosine_sim(attr_vec_glove, race2_vec_glove)\n",
        "                glove_race_biases.append(race1_sim_glove - race2_sim_glove)\n",
        "\n",
        "            attr_vec_w2v = get_word_vector(attribute, word2vec_embeddings)\n",
        "            race1_vec_w2v = get_word_vector(race1, word2vec_embeddings)\n",
        "            race2_vec_w2v = get_word_vector(race2, word2vec_embeddings)\n",
        "\n",
        "            if attr_vec_w2v is not None and race1_vec_w2v is not None and race2_vec_w2v is not None:\n",
        "                race1_sim_w2v = cosine_sim(attr_vec_w2v, race1_vec_w2v)\n",
        "                race2_sim_w2v = cosine_sim(attr_vec_w2v, race2_vec_w2v)\n",
        "                word2vec_race_biases.append(race1_sim_w2v - race2_sim_w2v)\n",
        "\n",
        "        if glove_race_biases and word2vec_race_biases:\n",
        "            results.append({\n",
        "                'attribute': attribute,\n",
        "                'glove_bias': np.mean(glove_race_biases),\n",
        "                'word2vec_bias': np.mean(word2vec_race_biases)\n",
        "            })\n",
        "\n",
        "    if results:\n",
        "        df = pd.DataFrame(results)\n",
        "        df['avg_bias'] = (df['glove_bias'] + df['word2vec_bias']) / 2\n",
        "        df = df.sort_values(by='avg_bias', ascending=False).drop('avg_bias', axis=1)\n",
        "\n",
        "        plt.figure(figsize=(14, 10))\n",
        "        x = np.arange(len(df))\n",
        "        width = 0.35\n",
        "\n",
        "        plt.bar(x - width/2, df['glove_bias'], width, label='GloVe')\n",
        "        plt.bar(x + width/2, df['word2vec_bias'], width, label='Word2Vec')\n",
        "\n",
        "        plt.axhline(y=0, color='r', linestyle='--')\n",
        "        plt.xlabel('Attribute')\n",
        "        plt.ylabel('Racial Bias (White/European - Black/African/Asian/Latino Similarity)')\n",
        "        plt.title('Comparison of Racial Bias Across Embedding Types')\n",
        "        plt.xticks(x, df['attribute'], rotation=45, ha='right')\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('racial_bias_comparison.png')\n",
        "        plt.close()\n",
        "\n",
        "        correlation = np.corrcoef(df['glove_bias'], df['word2vec_bias'])[0, 1]\n",
        "        print(f\"Correlation between GloVe and Word2Vec racial biases: {correlation:.4f}\")\n",
        "\n",
        "        print(\"\\nAttributes most biased toward White/European people:\")\n",
        "        for embed_type in ['glove_bias', 'word2vec_bias']:\n",
        "            top_biased = df.sort_values(by=embed_type, ascending=False).head(5)\n",
        "            embed_name = 'GloVe' if embed_type == 'glove_bias' else 'Word2Vec'\n",
        "            print(f\"\\n{embed_name}:\")\n",
        "            for _, row in top_biased.iterrows():\n",
        "                print(f\"  {row['attribute']}: {row[embed_type]:.4f}\")\n",
        "\n",
        "        print(\"\\nAttributes most biased toward Black/African/Asian/Latino people:\")\n",
        "        for embed_type in ['glove_bias', 'word2vec_bias']:\n",
        "            bottom_biased = df.sort_values(by=embed_type, ascending=True).head(5)\n",
        "            embed_name = 'GloVe' if embed_type == 'glove_bias' else 'Word2Vec'\n",
        "            print(f\"\\n{embed_name}:\")\n",
        "            for _, row in bottom_biased.iterrows():\n",
        "                print(f\"  {row['attribute']}: {row[embed_type]:.4f}\")\n",
        "\n",
        "        glove_avg_bias = df['glove_bias'].abs().mean()\n",
        "        word2vec_avg_bias = df['word2vec_bias'].abs().mean()\n",
        "        print(f\"\\nAverage absolute racial bias:\")\n",
        "        print(f\"GloVe: {glove_avg_bias:.4f}\")\n",
        "        print(f\"Word2Vec: {word2vec_avg_bias:.4f}\")\n",
        "    else:\n",
        "        print(\"No results to display. Check if words exist in both embeddings.\")\n",
        "\n",
        "    return df if results else None\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "  compare_racial_bias(glove, word2vec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASX_kmere4CX"
      },
      "source": [
        "## Extrinsic Evaluation via Sentiment Analysis\n",
        "\n",
        "\n",
        "\n",
        "*   We'll evaluate bias in downstream tasks by analyzing how embeddings impact sentiment analysis predictions.\n",
        "*   We create standardardized templates with gender/race terms and particular topics and use them to test gender-specific or race-specific words against these templates.\n",
        "\n",
        "*   This is done to understand how classification accuracy differs across genders/races and observe if models predict better for certain groups.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tE7NZauy2tEZ"
      },
      "source": [
        "### Gender Bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQHKHDuke5cI"
      },
      "outputs": [],
      "source": [
        "def get_sentiment_dataset():\n",
        "    templates = [\n",
        "        \"The {gender} talked about the {topic}.\",\n",
        "        \"The {gender} considered the {topic}.\",\n",
        "        \"The {gender} reviewed the {topic}.\",\n",
        "        \"The {gender} mentioned the {topic}.\"\n",
        "    ]\n",
        "\n",
        "    male_terms = [\"man\", \"father\", \"brother\", \"son\", \"uncle\", \"grandfather\", \"husband\", \"boyfriend\"]\n",
        "    female_terms = [\"woman\", \"mother\", \"sister\", \"daughter\", \"aunt\", \"grandmother\", \"wife\", \"girlfriend\"]\n",
        "\n",
        "    positive_terms = [\"happy\", \"pleased\", \"satisfied\", \"delighted\", \"glad\", \"excited\", \"content\", \"optimistic\"]\n",
        "    negative_terms = [\"sad\", \"displeased\", \"dissatisfied\", \"unhappy\", \"disappointed\", \"upset\", \"distressed\", \"pessimistic\"]\n",
        "\n",
        "    topics = [\"movie\", \"dinner\", \"meeting\", \"project\", \"trip\", \"news\", \"presentation\", \"article\"]\n",
        "\n",
        "    data = []\n",
        "\n",
        "    for template in templates:\n",
        "        for gender_list, gender_label in [(male_terms, \"male\"), (female_terms, \"female\")]:\n",
        "            for gender in gender_list:\n",
        "                for positive in positive_terms:\n",
        "                    for topic in topics:\n",
        "                        sentence = template.format(gender=gender, sentiment=positive, topic=topic)\n",
        "                        data.append((sentence, 1, gender_label))  # 1 = positive\n",
        "\n",
        "                for negative in negative_terms:\n",
        "                    for topic in topics:\n",
        "                        sentence = template.format(gender=gender, sentiment=negative, topic=topic)\n",
        "                        data.append((sentence, 0, gender_label))  # 0 = negative\n",
        "\n",
        "    random.shuffle(data)\n",
        "    sentences, labels, gender_labels = zip(*data)\n",
        "    return sentences, np.array(labels), np.array(gender_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vh8n6vvhfCuj"
      },
      "outputs": [],
      "source": [
        "def sentence_to_embedding(sentence, embeddings):\n",
        "    words = sentence.lower().split()\n",
        "    vectors = [get_word_vector(word, embeddings) for word in words]\n",
        "    vectors = [v for v in vectors if v is not None]\n",
        "    if not vectors:\n",
        "        return None\n",
        "\n",
        "    return np.mean(vectors, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wS5tK472fF9V",
        "outputId": "266f27b7-f4bc-45f4-b52c-8ad7f0d1d3b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating sentiment analysis bias with Word2vec:\n",
            "Overall accuracy: 0.4545\n",
            "Male accuracy: 0.4430\n",
            "Female accuracy: 0.4663\n",
            "Male positive accuracy: 0.5533\n",
            "Male negative accuracy: 0.3373\n",
            "Female positive accuracy: 0.3413\n",
            "Female negative accuracy: 0.5965\n",
            "\n",
            "Evaluating sentiment analysis bias with GLoVe:\n",
            "Overall accuracy: 0.4680\n",
            "Male accuracy: 0.4743\n",
            "Female accuracy: 0.4610\n",
            "Male positive accuracy: 0.3782\n",
            "Male negative accuracy: 0.5718\n",
            "Female positive accuracy: 0.5464\n",
            "Female negative accuracy: 0.3772\n"
          ]
        }
      ],
      "source": [
        "def evaluate_sentiment_bias(embeddings, name):\n",
        "    print(f\"\\nEvaluating sentiment analysis bias with {name}:\")\n",
        "\n",
        "    sentences, labels, gender_labels = get_sentiment_dataset()\n",
        "    X = []\n",
        "    valid_indices = []\n",
        "\n",
        "    for i, sentence in enumerate(sentences):\n",
        "        embedding = sentence_to_embedding(sentence, embeddings)\n",
        "        if embedding is not None:\n",
        "            X.append(embedding)\n",
        "            valid_indices.append(i)\n",
        "\n",
        "    if not X:\n",
        "        print(f\"No valid embeddings found for sentences using {name}\")\n",
        "        return\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = labels[valid_indices]\n",
        "    genders = gender_labels[valid_indices]\n",
        "\n",
        "    X_train, X_test, y_train, y_test, genders_train, genders_test = train_test_split(\n",
        "        X, y, genders, test_size=0.2, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    clf = LogisticRegression(random_state=42, max_iter=1000)\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = clf.predict(X_test)\n",
        "    print(f\"Overall accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "\n",
        "    male_indices = (genders_test == 'male')\n",
        "    female_indices = (genders_test == 'female')\n",
        "\n",
        "    male_acc = accuracy_score(y_test[male_indices], y_pred[male_indices])\n",
        "    female_acc = accuracy_score(y_test[female_indices], y_pred[female_indices])\n",
        "\n",
        "    print(f\"Male accuracy: {male_acc:.4f}\")\n",
        "    print(f\"Female accuracy: {female_acc:.4f}\")\n",
        "\n",
        "    # analyze misclassifications by sentiment and gender\n",
        "    male_positive_indices = np.logical_and(male_indices, y_test == 1)\n",
        "    male_negative_indices = np.logical_and(male_indices, y_test == 0)\n",
        "    female_positive_indices = np.logical_and(female_indices, y_test == 1)\n",
        "    female_negative_indices = np.logical_and(female_indices, y_test == 0)\n",
        "\n",
        "    male_positive_acc = accuracy_score(y_test[male_positive_indices], y_pred[male_positive_indices])\n",
        "    male_negative_acc = accuracy_score(y_test[male_negative_indices], y_pred[male_negative_indices])\n",
        "    female_positive_acc = accuracy_score(y_test[female_positive_indices], y_pred[female_positive_indices])\n",
        "    female_negative_acc = accuracy_score(y_test[female_negative_indices], y_pred[female_negative_indices])\n",
        "\n",
        "    print(f\"Male positive accuracy: {male_positive_acc:.4f}\")\n",
        "    print(f\"Male negative accuracy: {male_negative_acc:.4f}\")\n",
        "    print(f\"Female positive accuracy: {female_positive_acc:.4f}\")\n",
        "    print(f\"Female negative accuracy: {female_negative_acc:.4f}\")\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    categories = ['Overall', 'Male', 'Female', 'Male+', 'Male-', 'Female+', 'Female-']\n",
        "    accuracies = [\n",
        "        accuracy_score(y_test, y_pred),\n",
        "        male_acc,\n",
        "        female_acc,\n",
        "        male_positive_acc,\n",
        "        male_negative_acc,\n",
        "        female_positive_acc,\n",
        "        female_negative_acc\n",
        "    ]\n",
        "\n",
        "    plt.bar(categories, accuracies, color='skyblue')\n",
        "    plt.axhline(y=0.5, color='r', linestyle='--', label='Random Baseline')\n",
        "    plt.ylim(0.4, 1.0)\n",
        "    plt.title(f'Sentiment Classification Accuracy by Gender using {name}')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'sentiment_bias_{name}.png')\n",
        "    plt.close()\n",
        "    return accuracy_score(y_test, y_pred), male_acc, female_acc\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "  evaluate_sentiment_bias(word2vec, 'Word2vec')\n",
        "  evaluate_sentiment_bias(glove, 'GLoVe')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNLCk2Wn48bU"
      },
      "source": [
        "### Racial Bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fS7xHfD76QaR"
      },
      "outputs": [],
      "source": [
        "def get_racial_sentiment_dataset():\n",
        "    templates = [\n",
        "        \"The {race} perspective on {topic} leans {sentiment}.\",\n",
        "        \"{race} individuals found the {topic} somewhat {sentiment}.\",\n",
        "        \"The {topic} was met with {sentiment} views by {race} communities.\",\n",
        "        \"{race} responses to the {topic} had {sentiment} undertones.\",\n",
        "        \"The {topic}'s reception among {race} groups seemed {sentiment}.\"\n",
        "    ]\n",
        "\n",
        "    white_terms = [\"white\", \"caucasian\", \"european\", \"western\"]\n",
        "    black_terms = [\"black\", \"african\", \"african-american\"]\n",
        "    asian_terms = [\"asian\", \"east asian\", \"southeast asian\"]\n",
        "    latino_terms = [\"latino\", \"latina\", \"hispanic\", \"latinx\"]\n",
        "\n",
        "    positive_terms = [\"happy\", \"pleased\", \"satisfied\", \"delighted\", \"glad\", \"excited\", \"content\", \"optimistic\"]\n",
        "    negative_terms = [\"sad\", \"displeased\", \"dissatisfied\", \"unhappy\", \"disappointed\", \"upset\", \"distressed\", \"pessimistic\"]\n",
        "\n",
        "    topics = [\"event\", \"meeting\", \"discussion\", \"interview\", \"application\", \"interaction\", \"conversation\", \"experience\"]\n",
        "\n",
        "    data = []\n",
        "\n",
        "    racial_groups = [\n",
        "        (white_terms, \"white\"),\n",
        "        (black_terms, \"black\"),\n",
        "        (asian_terms, \"asian\"),\n",
        "        (latino_terms, \"latino\")\n",
        "    ]\n",
        "\n",
        "    for template in templates:\n",
        "        for race_terms, race_label in racial_groups:\n",
        "            for race in race_terms:\n",
        "                for positive in positive_terms:\n",
        "                    for topic in topics:\n",
        "                        sentence = template.format(race=race, sentiment=positive, topic=topic)\n",
        "                        data.append((sentence, 1, race_label))\n",
        "                for negative in negative_terms:\n",
        "                    for topic in topics:\n",
        "                        sentence = template.format(race=race, sentiment=negative, topic=topic)\n",
        "                        data.append((sentence, 0, race_label))\n",
        "\n",
        "    random.shuffle(data)\n",
        "\n",
        "    sentences, labels, race_labels = zip(*data)\n",
        "\n",
        "    return sentences, np.array(labels), np.array(race_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZopLs4-w6sN_"
      },
      "outputs": [],
      "source": [
        "def evaluate_racial_sentiment_bias(embeddings, name):\n",
        "    print(f\"\\nEvaluating racial sentiment bias with {name}:\")\n",
        "\n",
        "    sentences, labels, race_labels = get_racial_sentiment_dataset()\n",
        "\n",
        "    X = []\n",
        "    valid_indices = []\n",
        "\n",
        "    for i, sentence in enumerate(sentences):\n",
        "        embedding = sentence_to_embedding(sentence, embeddings)\n",
        "        if embedding is not None:\n",
        "            X.append(embedding)\n",
        "            valid_indices.append(i)\n",
        "\n",
        "    if not X:\n",
        "        print(f\"No valid embeddings found for sentences using {name}\")\n",
        "        return\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = labels[valid_indices]\n",
        "    races = race_labels[valid_indices]\n",
        "\n",
        "    X_train, X_test, y_train, y_test, races_train, races_test = train_test_split(\n",
        "        X, y, races, test_size=0.2, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    clf = LogisticRegression(random_state=42, max_iter=1000, C=0.1)\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = clf.predict(X_test)\n",
        "    print(f\"Overall accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "\n",
        "    unique_races = np.unique(races_test)\n",
        "    race_accuracies = {}\n",
        "\n",
        "    for race in unique_races:\n",
        "        race_indices = (races_test == race)\n",
        "        race_acc = accuracy_score(y_test[race_indices], y_pred[race_indices])\n",
        "        race_accuracies[race] = race_acc\n",
        "        print(f\"{race.capitalize()} accuracy: {race_acc:.4f}\")\n",
        "\n",
        "    results = []\n",
        "    for race in unique_races:\n",
        "        race_indices = (races_test == race)\n",
        "\n",
        "        race_positive_indices = np.logical_and(race_indices, y_test == 1)\n",
        "        race_negative_indices = np.logical_and(race_indices, y_test == 0)\n",
        "\n",
        "        if sum(race_positive_indices) > 0:\n",
        "            pos_acc = accuracy_score(y_test[race_positive_indices], y_pred[race_positive_indices])\n",
        "            print(f\"{race.capitalize()} positive accuracy: {pos_acc:.4f}\")\n",
        "            results.append({\n",
        "                'race': race,\n",
        "                'sentiment': 'positive',\n",
        "                'accuracy': pos_acc\n",
        "            })\n",
        "\n",
        "        if sum(race_negative_indices) > 0:\n",
        "            neg_acc = accuracy_score(y_test[race_negative_indices], y_pred[race_negative_indices])\n",
        "            print(f\"{race.capitalize()} negative accuracy: {neg_acc:.4f}\")\n",
        "            results.append({\n",
        "                'race': race,\n",
        "                'sentiment': 'negative',\n",
        "                'accuracy': neg_acc\n",
        "            })\n",
        "\n",
        "    df = pd.DataFrame(results)\n",
        "    pivot_df = df.pivot(index='race', columns='sentiment', values='accuracy')\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    ax = sns.heatmap(pivot_df, annot=True, cmap='Blues', vmin=0.5, vmax=1.0)\n",
        "    plt.title(f'Sentiment Classification Accuracy by Race using {name}')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'racial_sentiment_bias_{name}.png')\n",
        "    plt.close()\n",
        "\n",
        "    max_diff = max(race_accuracies.values()) - min(race_accuracies.values())\n",
        "    print(f\"Maximum accuracy difference between racial groups: {max_diff:.4f}\")\n",
        "\n",
        "    return race_accuracies, results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyJ5CjcO7FGn",
        "outputId": "3c150954-589f-403c-931d-f6e2f9174840"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating racial sentiment bias with Word2vec:\n",
            "Overall accuracy: 0.6842\n",
            "Asian accuracy: 0.6817\n",
            "Black accuracy: 0.6797\n",
            "Latino accuracy: 0.6913\n",
            "White accuracy: 0.6813\n",
            "Asian positive accuracy: 0.5051\n",
            "Asian negative accuracy: 0.8729\n",
            "Black positive accuracy: 0.6576\n",
            "Black negative accuracy: 0.7000\n",
            "Latino positive accuracy: 0.7681\n",
            "Latino negative accuracy: 0.6151\n",
            "White positive accuracy: 0.6792\n",
            "White negative accuracy: 0.6835\n",
            "Maximum accuracy difference between racial groups: 0.0116\n",
            "\n",
            "Evaluating racial sentiment bias with GLoVe:\n",
            "Overall accuracy: 0.6931\n",
            "Asian accuracy: 0.7047\n",
            "Black accuracy: 0.7107\n",
            "Latino accuracy: 0.6863\n",
            "White accuracy: 0.6804\n",
            "Asian positive accuracy: 0.7072\n",
            "Asian negative accuracy: 0.7022\n",
            "Black positive accuracy: 0.6328\n",
            "Black negative accuracy: 0.7849\n",
            "Latino positive accuracy: 0.6466\n",
            "Latino negative accuracy: 0.7295\n",
            "White positive accuracy: 0.6875\n",
            "White negative accuracy: 0.6736\n",
            "Maximum accuracy difference between racial groups: 0.0304\n"
          ]
        }
      ],
      "source": [
        "if __name__==\"__main__\":\n",
        "  evaluate_racial_sentiment_bias(word2vec, 'Word2vec')\n",
        "  evaluate_racial_sentiment_bias(glove, 'GLoVe')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFDbFbLjsBap"
      },
      "source": [
        "# References\n",
        "\n",
        "1. Pennington, J., Socher, R., & Manning, C. D. (2014, October). Glove: Global vectors for word representation. In Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP) (pp. 1532-1543).\n",
        "\n",
        "2. Mikolov, T., Chen, K., Corrado, G., & Dean, J. (2013). Efficient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781.\n",
        "\n",
        "3. Caliskan, A., Bryson, J. J., & Narayanan, A. (2017). Semantics derived automatically from language corpora contain human-like biases. Science, 356(6334), 183-186.\n",
        "\n",
        "4. Text Embedding Models Contain Bias. Here's Why That Matters. https://developers.googleblog.com/en/text-embedding-models-contain-bias-heres-why-that-matters/\n",
        "\n",
        "5. chadaeun/weat_replication. https://github.com/chadaeun/weat_replication\n",
        "\n",
        "6. PLN-FaMAF/Bias-in-word-embeddings. https://github.com/PLN-FaMAF/Bias-in-word-embeddings\n",
        "\n",
        "7. Introduction to t-SNE. https://www.datacamp.com/tutorial/introduction-t-sne\n",
        "\n",
        "8. Word Embedding Fairness Evaluation. https://www.kdnuggets.com/2020/08/word-embedding-fairness-evaluation.html\n",
        "\n",
        "9. Bolukbasi, T., Chang, K. W., Zou, J. Y., Saligrama, V., & Kalai, A. T. (2016). Man is to computer programmer as woman is to homemaker? debiasing word embeddings. Advances in neural information processing systems, 29.\n",
        "\n",
        "10. Garg, N., Schiebinger, L., Jurafsky, D., & Zou, J. (2018). Word embeddings quantify 100 years of gender and ethnic stereotypes. Proceedings of the National Academy of Sciences, 115(16), E3635-E3644.\n",
        "\n",
        "11. Manzini, T., Lim, Y. C., Tsvetkov, Y., & Black, A. W. (2019). Black is to criminal as caucasian is to police: Detecting and removing multiclass bias in word embeddings. arXiv preprint arXiv:1904.04047.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
